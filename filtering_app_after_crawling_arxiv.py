import asyncio
import gradio as gr
import json
import os
from openai import AsyncOpenAI
import aiofiles
from pathlib import Path
import glob
import time

# é»˜è®¤é…ç½®
DEFAULT_CONFIG = {
    "api_key": "YOUR_API_KEY_HERE",
    "base_url": "https://api.openai.com/v1/",
    "model": "gpt-4-turbo",
    "rounds": 3,
    "max_concurrent": 50
}

# é¢„è®¾æç¤ºè¯
COARSE_SYSTEM_PROMPT = """
Determine if this paper title is related to emotional support, psychological counseling, or multi-turn dialogue. Return True if there is any relevant content, otherwise return False.
<True/False>
"""

FINE_SYSTEM_PROMPT = """
Please carefully read the title and abstract of the paper and determine whether the paper is closely related to any of the following topics:
- Emotional support
- Psychological counseling
- Multi-turn dialogue
- Dialogue systems

Please conduct an in-depth analysis based on the content of the abstract. Return "True" only if the core content of the paper is indeed related to the above topics.
If the paper only mentions relevant concepts slightly or mainly focuses on other fields, return "False".

<True/False>
"""

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = "config.json"
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            if "rounds" not in config:
                config["rounds"] = DEFAULT_CONFIG["rounds"]
            if "max_concurrent" not in config:
                config["max_concurrent"] = DEFAULT_CONFIG["max_concurrent"]
            return config
    else:
        # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(DEFAULT_CONFIG, f, ensure_ascii=False, indent=2)
        return DEFAULT_CONFIG

def save_config(api_key, base_url, model, rounds, max_concurrent):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    config = {
        "api_key": api_key,
        "base_url": base_url,
        "model": model,
        "rounds": int(rounds),
        "max_concurrent": int(max_concurrent)
    }
    with open("config.json", 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    return "é…ç½®å·²ä¿å­˜ï¼"

def get_json_files():
    """è·å–ä¸»ç›®å½•å’Œ arxiv_papers_new å­ç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶ï¼Œå¹¶åº”ç”¨è¿‡æ»¤è§„åˆ™"""
    # è·å–ä¸»ç›®å½•çš„æ–‡ä»¶
    main_dir_files = glob.glob("*.json")
    
    # è·å–å­ç›®å½•çš„æ–‡ä»¶
    sub_dir_path = "arxiv_papers_new"
    sub_dir_files = []
    if os.path.isdir(sub_dir_path):
        sub_dir_files = glob.glob(os.path.join(sub_dir_path, "*.json"))

    # åˆå¹¶ä¸¤ä¸ªåˆ—è¡¨
    all_files = main_dir_files + sub_dir_files

    # å®šä¹‰è¿‡æ»¤è§„åˆ™
    excluded_suffixes = ['_coarse_', '_fine_']
    excluded_filenames = ['config.json']
    subdir_excluded_filenames = ['last_crawl_time.json', 'failed_intervals.json']

    # åº”ç”¨è¿‡æ»¤
    filtered_list = []
    for file_path in all_files:
        base_name = os.path.basename(file_path)
        
        # è§„åˆ™1: è¿‡æ»¤æ‰ä¸­é—´ç»“æœæ–‡ä»¶
        if any(suffix in base_name for suffix in excluded_suffixes):
            continue
        
        # è§„åˆ™2: è¿‡æ»¤æ‰é…ç½®æ–‡ä»¶
        if base_name in excluded_filenames:
            continue
            
        # è§„åˆ™3: è¿‡æ»¤æ‰å­ç›®å½•ä¸‹çš„ç‰¹å®šæ–‡ä»¶
        # is_in_subdir = os.path.dirname(file_path) == sub_dir_path
        is_in_subdir = sub_dir_path in file_path
        if is_in_subdir and base_name in subdir_excluded_filenames:
            continue
        
        filtered_list.append(file_path)
        
    return filtered_list

def get_result_files():
    """è·å–å½“å‰ç›®å½•ä¸‹çš„ç²—ç­›ç»“æœæ–‡ä»¶"""
    return [f for f in glob.glob("*.json") if 'coarse_final' in f]


def get_filename_with_suffix(original_filename, suffix):
    """åœ¨æ–‡ä»¶åçš„.jsonä¹‹å‰æ·»åŠ åç¼€ï¼Œè¾“å‡ºæ–‡ä»¶ä¿å­˜åˆ°å½“å‰ç›®å½•"""
    base_filename = os.path.basename(original_filename)
    
    if base_filename.endswith('.json'):
        base_name = base_filename[:-5]  # å»æ‰.json
        return f"{base_name}_{suffix}.json"
    else:
        return f"{base_filename}_{suffix}"

async def check_paper_relevance_with_retry(client, paper_data, system_prompt, max_retries=3):
    """æ£€æŸ¥å•ä¸ªè®ºæ–‡çš„ç›¸å…³æ€§ï¼ˆç²—ç­›ï¼‰- å¸¦é‡è¯•æœºåˆ¶"""
    for attempt in range(max_retries):
        try:
            # å…¼å®¹æ€§ä¿®æ”¹ï¼šå®‰å…¨åœ°è·å–å’Œå¤„ç†æ ‡é¢˜ï¼Œä»¥å…¼å®¹æ–°æ—§ä¸¤ç§JSONæ ¼å¼
            title_text = paper_data.get('title', '').strip()
            # ä¿ç•™splité€»è¾‘ä»¥å…¼å®¹æ—§æ ¼å¼ï¼ŒåŒæ—¶å¯¹æ–°æ ¼å¼ä¹Ÿå®‰å…¨
            clean_title = title_text.split('author')[0].strip()
            user_content = f"è®ºæ–‡æ ‡é¢˜: {clean_title}"

            response = await client.chat.completions.create(
                model=client.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content}
                ]
            )
            result = response.choices[0].message.content.strip()
            return paper_data, "True" in result
        except Exception as e:
            if attempt < max_retries - 1:
                print(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                print("ç­‰å¾…60ç§’åé‡è¯•...")
                await asyncio.sleep(60)
            else:
                print(f"å¤„ç†æ ‡é¢˜ '{paper_data.get('title', 'N/A')}' æ—¶å‡ºé”™ (å·²é‡è¯•{max_retries}æ¬¡): {e}")
                return paper_data, False

async def check_paper_relevance_detailed_with_retry(client, paper_data, system_prompt, max_retries=3):
    """åŸºäºæ ‡é¢˜å’Œæ‘˜è¦æ£€æŸ¥å•ä¸ªè®ºæ–‡çš„ç›¸å…³æ€§ï¼ˆç²¾æ’ï¼‰- å¸¦é‡è¯•æœºåˆ¶"""
    for attempt in range(max_retries):
        try:
            # å…¼å®¹æ€§ä¿®æ”¹ï¼šå®‰å…¨åœ°è·å–å’Œå¤„ç†æ ‡é¢˜ä¸æ‘˜è¦
            title_text = paper_data.get('title', '').strip()
            abstract_text = paper_data.get('abstract', '').strip()
            # ä¿ç•™splité€»è¾‘ä»¥å…¼å®¹æ—§æ ¼å¼
            clean_title = title_text.split('author')[0].strip()
            content = f"è®ºæ–‡æ ‡é¢˜: {clean_title}\n\nè®ºæ–‡æ‘˜è¦: {abstract_text}"
            
            response = await client.chat.completions.create(
                model=client.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": content}
                ]
            )
            result = response.choices[0].message.content.strip()
            return paper_data, "True" in result
        except Exception as e:
            if attempt < max_retries - 1:
                print(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                print("ç­‰å¾…60ç§’åé‡è¯•...")
                await asyncio.sleep(60)
            else:
                print(f"å¤„ç†è®ºæ–‡ '{paper_data.get('title', 'N/A')}' æ—¶å‡ºé”™ (å·²é‡è¯•{max_retries}æ¬¡): {e}")
                return paper_data, False

async def process_papers_single_round(client, papers_data, system_prompt, round_num, max_concurrent, is_fine=False, progress_callback=None):
    """å•è½®å¤„ç†æ‰€æœ‰è®ºæ–‡"""
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def limited_check(paper_data):
        async with semaphore:
            if is_fine:
                return await check_paper_relevance_detailed_with_retry(client, paper_data, system_prompt)
            else:
                return await check_paper_relevance_with_retry(client, paper_data, system_prompt)
    
    mode = "ç²¾æ’" if is_fine else "ç²—ç­›"
    print(f"å¼€å§‹ç¬¬ {round_num} è½®{mode}æ£€æŸ¥ {len(papers_data)} ç¯‡è®ºæ–‡çš„ç›¸å…³æ€§...")
    
    tasks = [limited_check(paper) for paper in papers_data if paper.get('title')]
    
    results = []
    completed = 0
    
    for completed_task in asyncio.as_completed(tasks):
        result = await completed_task
        results.append(result)
        completed += 1
        
        if progress_callback and len(tasks) > 0:
            progress = completed / len(tasks)
            progress_callback(progress, f"ç¬¬{round_num}è½®{mode}: {completed}/{len(tasks)}")
    
    relevant_papers = [paper_data for paper_data, is_relevant in results if is_relevant]
    
    print(f"ç¬¬ {round_num} è½®{mode}æ‰¾åˆ° {len(relevant_papers)} ç¯‡ç›¸å…³è®ºæ–‡")
    
    return relevant_papers

async def coarse_screening(main_json_file, findings_json_file, system_prompt, config, progress_callback=None):
    """ç²—ç­›å¤„ç†"""
    papers_data = []
    
    if not os.path.exists(main_json_file):
        return f"é”™è¯¯ï¼šæ–‡ä»¶ {main_json_file} ä¸å­˜åœ¨"
    
    try:
        async with aiofiles.open(main_json_file, 'r', encoding='utf-8') as f:
            content = await f.read()
            main_data = json.loads(content)
            if 'papers' in main_data:
                papers_data.extend(main_data['papers'])
                print(f"è¯»å–ä¸»ä¼šè®®è®ºæ–‡: {len(main_data['papers'])} ç¯‡")
    except Exception as e:
        return f"è¯»å–æˆ–è§£æä¸»æ–‡ä»¶ {main_json_file} å¤±è´¥: {e}"

    if findings_json_file and os.path.exists(findings_json_file):
        try:
            async with aiofiles.open(findings_json_file, 'r', encoding='utf-8') as f:
                content = await f.read()
                findings_data = json.loads(content)
                if 'papers' in findings_data:
                    papers_data.extend(findings_data['papers'])
                    print(f"è¯»å–Findingsè®ºæ–‡: {len(findings_data['papers'])} ç¯‡")
        except Exception as e:
            return f"è¯»å–æˆ–è§£æFindingsæ–‡ä»¶ {findings_json_file} å¤±è´¥: {e}"

    
    print(f"æ€»å…±éœ€è¦å¤„ç†: {len(papers_data)} ç¯‡è®ºæ–‡")
    
    client = AsyncOpenAI(
        api_key=config["api_key"], 
        base_url=config["base_url"],
        timeout=60.0
    )
    client.model = config["model"]
    
    all_rounds_results = []
    rounds = config.get("rounds", 3)
    max_concurrent = config.get("max_concurrent", 50)
    
    for round_num in range(1, rounds + 1):
        if progress_callback:
            progress_callback(0, f"å¼€å§‹ç¬¬{round_num}è½®ç²—ç­›...")
        
        relevant_papers = await process_papers_single_round(
            client, papers_data, system_prompt, round_num, max_concurrent, False, progress_callback
        )
        all_rounds_results.append(relevant_papers)
        
        round_data = {
            "round": round_num,
            "total_papers": len(papers_data),
            "relevant_papers_count": len(relevant_papers),
            "relevant_papers": relevant_papers
        }
        
        output_file = get_filename_with_suffix(main_json_file, f'coarse_round_{round_num}')
        async with aiofiles.open(output_file, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(round_data, ensure_ascii=False, indent=2))
        
        print(f"ç¬¬ {round_num} è½®ç»“æœå·²ä¿å­˜åˆ° {output_file}")
    
    all_relevant_papers = {}
    for round_papers in all_rounds_results:
        for paper in round_papers:
            # ä½¿ç”¨æ ‡é¢˜ä½œä¸ºé”®æ¥å»é‡
            if paper.get('title'):
                all_relevant_papers[paper['title']] = paper
    
    final_relevant_papers = list(all_relevant_papers.values())
    
    final_data = {
        "total_papers": len(papers_data),
        "rounds_count": rounds,
        "max_concurrent": max_concurrent,
        "round_results": [
            {
                "round": i,
                "count": len(round_papers)
            }
            for i, round_papers in enumerate(all_rounds_results, 1)
        ],
        "final_relevant_papers_count": len(final_relevant_papers),
        "relevant_papers": sorted(final_relevant_papers, key=lambda x: x.get('title', ''))
    }
    
    output_file = get_filename_with_suffix(main_json_file, 'coarse_final')
    async with aiofiles.open(output_file, 'w', encoding='utf-8') as f:
        await f.write(json.dumps(final_data, ensure_ascii=False, indent=2))
    
    round_stats = "\n".join([f"- ç¬¬{i}è½®ç­›é€‰ï¼š{len(round_papers)} ç¯‡" for i, round_papers in enumerate(all_rounds_results, 1)])
    
    result_text = f"""
ç²—ç­›å®Œæˆï¼

å¤„ç†ç»Ÿè®¡ï¼š
- æ€»è®ºæ–‡æ•°ï¼š{len(papers_data)}
- å¤„ç†è½®æ•°ï¼š{rounds} è½®
- æœ€å¤§å¹¶å‘æ•°ï¼š{max_concurrent}
{round_stats}
- æœ€ç»ˆç»“æœï¼š{len(final_relevant_papers)} ç¯‡

ç»“æœå·²ä¿å­˜åˆ°ï¼š{output_file}
"""
    
    return result_text

async def fine_screening(input_json_file, system_prompt, config, progress_callback=None):
    """ç²¾æ’å¤„ç†"""
    if not os.path.exists(input_json_file):
        return f"é”™è¯¯ï¼šæ–‡ä»¶ {input_json_file} ä¸å­˜åœ¨"
    
    try:
        async with aiofiles.open(input_json_file, 'r', encoding='utf-8') as f:
            content = await f.read()
            coarse_data = json.loads(content)
            papers_data = coarse_data.get('relevant_papers', [])
            print(f"è¯»å–ç²—æ’ç»“æœ: {len(papers_data)} ç¯‡è®ºæ–‡")
    except Exception as e:
        return f"è¯»å–æˆ–è§£ææ–‡ä»¶ {input_json_file} å¤±è´¥: {e}"

    client = AsyncOpenAI(
        api_key=config["api_key"], 
        base_url=config["base_url"],
        timeout=60.0
    )
    client.model = config["model"]
    
    all_rounds_results = []
    rounds = config.get("rounds", 3)
    max_concurrent = min(config.get("max_concurrent", 50), 30)
    
    for round_num in range(1, rounds + 1):
        if progress_callback:
            progress_callback(0, f"å¼€å§‹ç¬¬{round_num}è½®ç²¾æ’...")
        
        relevant_papers = await process_papers_single_round(
            client, papers_data, system_prompt, round_num, max_concurrent, True, progress_callback
        )
        all_rounds_results.append(relevant_papers)
        
        round_data = {
            "round": round_num,
            "type": "fine_ranking",
            "input_papers": len(papers_data),
            "relevant_papers_count": len(relevant_papers),
            "relevant_papers": relevant_papers
        }
        
        output_file = get_filename_with_suffix(input_json_file, f'fine_round_{round_num}')
        async with aiofiles.open(output_file, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(round_data, ensure_ascii=False, indent=2))
        
        print(f"ç¬¬ {round_num} è½®ç²¾æ’ç»“æœå·²ä¿å­˜åˆ° {output_file}")
    
    all_relevant_papers = {}
    for round_papers in all_rounds_results:
        for paper in round_papers:
            if paper.get('title'):
                all_relevant_papers[paper['title']] = paper
    
    final_relevant_papers = list(all_relevant_papers.values())
    
    final_data = {
        "type": "fine_ranking_final",
        "input_papers": len(papers_data),
        "rounds_count": rounds,
        "max_concurrent": max_concurrent,
        "round_results": [
            {
                "round": i,
                "count": len(round_papers)
            }
            for i, round_papers in enumerate(all_rounds_results, 1)
        ],
        "final_relevant_papers_count": len(final_relevant_papers),
        "selection_rate": f"{len(final_relevant_papers)/len(papers_data)*100:.1f}%" if len(papers_data) > 0 else "0.0%",
        "relevant_papers": sorted(final_relevant_papers, key=lambda x: x.get('title', ''))
    }
    
    output_file = get_filename_with_suffix(input_json_file, 'fine_final')
    async with aiofiles.open(output_file, 'w', encoding='utf-8') as f:
        await f.write(json.dumps(final_data, ensure_ascii=False, indent=2))
    
    round_stats = "\n".join([f"- ç¬¬{i}è½®ç²¾æ’ï¼š{len(round_papers)} ç¯‡" for i, round_papers in enumerate(all_rounds_results, 1)])
    
    result_text = f"""
ç²¾æ’å®Œæˆï¼

å¤„ç†ç»Ÿè®¡ï¼š
- è¾“å…¥è®ºæ–‡æ•°ï¼š{len(papers_data)}
- å¤„ç†è½®æ•°ï¼š{rounds} è½®
- æœ€å¤§å¹¶å‘æ•°ï¼š{max_concurrent}
{round_stats}
- æœ€ç»ˆç»“æœï¼š{len(final_relevant_papers)} ç¯‡
- ç²¾æ’ç‡ï¼š{final_data['selection_rate']}

ç»“æœå·²ä¿å­˜åˆ°ï¼š{output_file}
"""
    
    return result_text

def get_file_path(dropdown_value, upload_file):
    """è·å–æ–‡ä»¶è·¯å¾„ï¼Œä¼˜å…ˆä½¿ç”¨ä¸Šä¼ çš„æ–‡ä»¶"""
    if upload_file is not None:
        return upload_file.name
    elif dropdown_value:
        return dropdown_value
    else:
        return None

def run_coarse_screening_with_progress(main_dropdown, findings_dropdown, main_upload, findings_upload, system_prompt, progress=gr.Progress()):
    def progress_callback(prog, desc):
        progress(prog, desc=desc)
    
    main_file = get_file_path(main_dropdown, main_upload)
    findings_file = get_file_path(findings_dropdown, findings_upload)
    
    if not main_file:
        return "é”™è¯¯ï¼šè¯·é€‰æ‹©ä¸»ä¼šè®®è®ºæ–‡æ–‡ä»¶"
    
    config = load_config()
    return asyncio.run(coarse_screening(main_file, findings_file, system_prompt, config, progress_callback))

def run_fine_screening_with_progress(input_dropdown, input_upload, system_prompt, progress=gr.Progress()):
    def progress_callback(prog, desc):
        progress(prog, desc=desc)
    
    input_file = get_file_path(input_dropdown, input_upload)
    
    if not input_file:
        return "é”™è¯¯ï¼šè¯·é€‰æ‹©è¾“å…¥æ–‡ä»¶"
    
    config = load_config()
    return asyncio.run(fine_screening(input_file, system_prompt, config, progress_callback))

# åˆ›å»ºGradioç•Œé¢
def create_interface():
    config = load_config()
    
    with gr.Blocks(title="è®ºæ–‡ç­›é€‰ç³»ç»Ÿ", theme=gr.themes.Soft()) as app:
        gr.Markdown("# ğŸ” è®ºæ–‡ç­›é€‰ç³»ç»Ÿ")
        gr.Markdown("æ”¯æŒç²—ç­›å’Œç²¾æ’ä¸¤ä¸ªé˜¶æ®µçš„è®ºæ–‡ç­›é€‰ï¼Œä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ™ºèƒ½åˆ†æ")
        
        with gr.Tabs():
            # é…ç½®æ ‡ç­¾é¡µ
            with gr.TabItem("âš™ï¸ é…ç½®"):
                gr.Markdown("### å¤§æ¨¡å‹é…ç½®")
                gr.Markdown("âš ï¸ **æ³¨æ„**ï¼šè¯·ç¡®ä¿APIå¯†é’¥å’ŒURLçš„æ­£ç¡®æ€§")
                
                with gr.Row():
                    with gr.Column():
                        api_key_input = gr.Textbox(
                            label="API Key",
                            value=config["api_key"],
                            type="password"
                        )
                        base_url_input = gr.Textbox(
                            label="Base URL",
                            value=config["base_url"]
                        )
                        model_input = gr.Textbox(
                            label="æ¨¡å‹åç§°",
                            value=config["model"]
                        )
                    
                    with gr.Column():
                        rounds_input = gr.Slider(
                            label="å¤„ç†è½®æ•°",
                            minimum=1,
                            maximum=10,
                            step=1,
                            value=config.get("rounds", 3),
                            info="è®¾ç½®ç­›é€‰çš„è½®æ•°ï¼Œå¤šè½®ç­›é€‰å¯ä»¥æé«˜å‡†ç¡®æ€§"
                        )
                        max_concurrent_input = gr.Slider(
                            label="æœ€å¤§å¹¶å‘æ•°",
                            minimum=1,
                            maximum=200,
                            step=1,
                            value=config.get("max_concurrent", 50),
                            info="âš ï¸ æ³¨æ„ï¼šAPIæä¾›å•†å¯èƒ½æœ‰å¹¶å‘é™åˆ¶ï¼Œå»ºè®®ä»è¾ƒå°å€¼å¼€å§‹æµ‹è¯•"
                        )
                        
                        gr.Markdown("""
                        **å¹¶å‘è¯´æ˜**ï¼š
                        - å¹¶å‘æ•°è¿‡é«˜å¯èƒ½å¯¼è‡´APIé™æµ
                        - è°ƒç”¨å¤±è´¥æ—¶ç³»ç»Ÿä¼šè‡ªåŠ¨æš‚åœ1åˆ†é’Ÿåé‡è¯•
                        - ç²¾æ’é˜¶æ®µä¼šè‡ªåŠ¨é™ä½å¹¶å‘æ•°ä»¥æé«˜ç¨³å®šæ€§
                        """)
                
                save_config_btn = gr.Button("ğŸ’¾ ä¿å­˜é…ç½®", variant="primary")
                config_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
                
                save_config_btn.click(
                    save_config,
                    inputs=[api_key_input, base_url_input, model_input, rounds_input, max_concurrent_input],
                    outputs=config_status
                )
            
            # ç²—ç­›æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ” ç²—ç­›"):
                gr.Markdown("### ç²—ç­›é˜¶æ®µ")
                gr.Markdown("åŸºäºè®ºæ–‡æ ‡é¢˜è¿›è¡Œåˆæ­¥ç­›é€‰ï¼Œå¿«é€Ÿè¿‡æ»¤å¤§é‡è®ºæ–‡")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("**ä¸»ä¼šè®®è®ºæ–‡æ–‡ä»¶**")
                        main_file_dropdown = gr.Dropdown(
                            # --- ä¿®æ”¹ç‚¹ 3: ä½¿ç”¨æ–°å‡½æ•°åˆå§‹åŒ–åˆ—è¡¨ ---
                            choices=get_json_files(),
                            label="ä»åˆ—è¡¨é€‰æ‹©",
                            info="ä»ä¸»ç›®å½•æˆ– arxiv_papers_new ç›®å½•é€‰æ‹©æ–‡ä»¶"
                        )
                        main_file_upload = gr.File(
                            label="æˆ–ä»ç³»ç»Ÿé€‰æ‹©",
                            file_types=[".json"]
                        )
                        
                        gr.Markdown("**Findingsè®ºæ–‡æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰**")
                        findings_file_dropdown = gr.Dropdown(
                            # --- ä¿®æ”¹ç‚¹ 3: ä½¿ç”¨æ–°å‡½æ•°åˆå§‹åŒ–åˆ—è¡¨ ---
                            choices=[""] + get_json_files(),
                            label="ä»åˆ—è¡¨é€‰æ‹©",
                            info="ä»ä¸»ç›®å½•æˆ– arxiv_papers_new ç›®å½•é€‰æ‹©æ–‡ä»¶"
                        )
                        findings_file_upload = gr.File(
                            label="æˆ–ä»ç³»ç»Ÿé€‰æ‹©",
                            file_types=[".json"]
                        )
                        
                        refresh_files_btn = gr.Button("ğŸ”„ åˆ·æ–°æ–‡ä»¶åˆ—è¡¨")
                        
                    with gr.Column(scale=2):
                        coarse_prompt = gr.Textbox(
                            label="ç²—ç­›æç¤ºè¯",
                            value=COARSE_SYSTEM_PROMPT,
                            lines=8,
                            info="âš ï¸ è¯·ä¿æŒè¾“å‡ºæ ¼å¼ <True/False> ä¸å˜"
                        )
                
                run_coarse_btn = gr.Button("ğŸš€ å¼€å§‹ç²—ç­›", variant="primary", size="lg")
                coarse_output = gr.Textbox(
                    label="ç²—ç­›ç»“æœ",
                    lines=12,
                    interactive=False
                )
                
                run_coarse_btn.click(
                    run_coarse_screening_with_progress,
                    inputs=[main_file_dropdown, findings_file_dropdown, main_file_upload, findings_file_upload, coarse_prompt],
                    outputs=coarse_output
                )
            
            # ç²¾æ’æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ¯ ç²¾æ’"):
                gr.Markdown("### ç²¾æ’é˜¶æ®µ")
                gr.Markdown("åŸºäºè®ºæ–‡æ ‡é¢˜å’Œæ‘˜è¦è¿›è¡Œç²¾ç»†ç­›é€‰ï¼Œæé«˜ç­›é€‰è´¨é‡")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        gr.Markdown("**ç²—ç­›ç»“æœæ–‡ä»¶**")
                        input_file_dropdown = gr.Dropdown(
                            # --- ä¿®æ”¹ç‚¹ 3: ä½¿ç”¨æ–°å‡½æ•°åˆå§‹åŒ–åˆ—è¡¨ ---
                            choices=get_result_files(),
                            label="ä»åˆ—è¡¨é€‰æ‹©",
                            info="é€‰æ‹©å½“å‰ç›®å½•ä¸‹çš„ç²—ç­›ç»“æœæ–‡ä»¶"
                        )
                        input_file_upload = gr.File(
                            label="æˆ–ä»ç³»ç»Ÿé€‰æ‹©",
                            file_types=[".json"]
                        )
                        refresh_input_files_btn = gr.Button("ğŸ”„ åˆ·æ–°ç»“æœæ–‡ä»¶")
                        
                    with gr.Column(scale=2):
                        fine_prompt = gr.Textbox(
                            label="ç²¾æ’æç¤ºè¯",
                            value=FINE_SYSTEM_PROMPT,
                            lines=10,
                            info="âš ï¸ è¯·ä¿æŒè¾“å‡ºæ ¼å¼ <True/False> ä¸å˜"
                        )
                
                run_fine_btn = gr.Button("ğŸ¯ å¼€å§‹ç²¾æ’", variant="primary", size="lg")
                fine_output = gr.Textbox(
                    label="ç²¾æ’ç»“æœ",
                    lines=12,
                    interactive=False
                )
                
                run_fine_btn.click(
                    run_fine_screening_with_progress,
                    inputs=[input_file_dropdown, input_file_upload, fine_prompt],
                    outputs=fine_output
                )
            
            # å¸®åŠ©æ ‡ç­¾é¡µ
            with gr.TabItem("â“ å¸®åŠ©"):
                gr.Markdown("""
                ### ä½¿ç”¨è¯´æ˜
                
                #### 1. é…ç½®è®¾ç½®
                - åœ¨"é…ç½®"æ ‡ç­¾é¡µä¸­è®¾ç½®æ‚¨çš„APIå¯†é’¥ã€Base URLå’Œæ¨¡å‹åç§°
                - **å¤„ç†è½®æ•°**ï¼šé»˜è®¤3è½®ï¼Œå¤šè½®å¤„ç†å¯ä»¥æé«˜ç­›é€‰çš„å‡†ç¡®æ€§å’Œå¬å›ç‡
                - **æœ€å¤§å¹¶å‘æ•°**ï¼šæ§åˆ¶åŒæ—¶å‘é€çš„APIè¯·æ±‚æ•°é‡ï¼Œå»ºè®®ä»50å¼€å§‹æµ‹è¯•
                - é…ç½®ä¼šè‡ªåŠ¨ä¿å­˜åˆ° `config.json` æ–‡ä»¶ä¸­
                
                #### 2. ç²—ç­›æµç¨‹
                - ä»ä¸‹æ‹‰åˆ—è¡¨é€‰æ‹©è®ºæ–‡JSONæ–‡ä»¶ï¼ˆå¯æ¥è‡ªä¸»ç›®å½•æˆ–`arxiv_papers_new`å­ç›®å½•ï¼‰
                - å¯é€‰æ‹©æ·»åŠ Findingsè®ºæ–‡æ–‡ä»¶
                - ç³»ç»Ÿä¼šè¿›è¡Œå¤šè½®ç­›é€‰å¹¶å–å¹¶é›†ä½œä¸ºæœ€ç»ˆç»“æœ
                - ç»“æœä¿å­˜ä¸º `åŸæ–‡ä»¶å_coarse_final.json`
                
                #### 3. ç²¾æ’æµç¨‹
                - é€‰æ‹©ç²—ç­›é˜¶æ®µçš„è¾“å‡ºæ–‡ä»¶
                - åŸºäºæ ‡é¢˜å’Œæ‘˜è¦è¿›è¡Œæ›´ç²¾ç¡®çš„ç­›é€‰
                - åŒæ ·è¿›è¡Œå¤šè½®ç­›é€‰å¹¶å–å¹¶é›†
                - ç»“æœä¿å­˜ä¸º `åŸæ–‡ä»¶å_fine_final.json`
                
                #### 4. æ–‡ä»¶å‘½åè§„åˆ™
                - ç²—ç­›ç»“æœï¼š`åŸæ–‡ä»¶å_coarse_final.json`
                - ç²¾æ’ç»“æœï¼š`åŸæ–‡ä»¶å_fine_final.json`
                - ä¸­é—´ç»“æœï¼š`åŸæ–‡ä»¶å_coarse_round_X.json` / `åŸæ–‡ä»¶å_fine_round_X.json`
                """)
        
        # --- ä¿®æ”¹ç‚¹ 4: æ›´æ–°åˆ·æ–°å‡½æ•°ä»¥è°ƒç”¨æ–°å‡½æ•° ---
        def refresh_files():
            """åˆ·æ–°æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨"""
            input_files = get_json_files()
            result_files = get_result_files()
            return (
                gr.update(choices=input_files), 
                gr.update(choices=[""] + input_files), 
                gr.update(choices=result_files)
            )
        
        refresh_files_btn.click(
            refresh_files,
            outputs=[main_file_dropdown, findings_file_dropdown, input_file_dropdown]
        )
        
        refresh_input_files_btn.click(
            refresh_files,
            outputs=[main_file_dropdown, findings_file_dropdown, input_file_dropdown]
        )
    
    return app

if __name__ == "__main__":
    if not os.path.exists("arxiv_papers_new"):
        os.makedirs("arxiv_papers_new")

    app = create_interface()
    app.launch(
        server_name="0.0.0.0",
        server_port=7898,
        share=False,
        show_error=True
    )
